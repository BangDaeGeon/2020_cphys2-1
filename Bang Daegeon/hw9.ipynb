{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import models \n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "# preprocessing\n",
    "X_train = X_train.reshape((60000, 28*28))\n",
    "X_train = X_train/255\n",
    "\n",
    "X_test = X_test.reshape((10000, 28*28))\n",
    "X_test = X_test/255\n",
    "\n",
    "net = models.Sequential()\n",
    "net.add(layers.Dense(512, activation='relu', input_shape=(28*28,))) \n",
    "net.add(layers.Dense(512, activation='relu')) \n",
    "net.add(layers.Dropout(0.5))\n",
    "net.add(layers.Dense(512, activation='relu')) \n",
    "net.add(layers.Dropout(0.5))\n",
    "net.add(layers.Dense(10, activation='softmax')) \n",
    "net.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:10000]\n",
    "partial_X_train = X_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5589 - acc: 0.7993 - val_loss: 0.8059 - val_acc: 0.7553\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3964 - acc: 0.8560 - val_loss: 0.4173 - val_acc: 0.8522\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3561 - acc: 0.8708 - val_loss: 0.3703 - val_acc: 0.8633\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3279 - acc: 0.8810 - val_loss: 0.3168 - val_acc: 0.8838\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3100 - acc: 0.8858 - val_loss: 0.3174 - val_acc: 0.8808\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3001 - acc: 0.8909 - val_loss: 0.3191 - val_acc: 0.8844\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.2861 - acc: 0.8944 - val_loss: 0.3322 - val_acc: 0.8795\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.2759 - acc: 0.8996 - val_loss: 0.3098 - val_acc: 0.8875\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.2656 - acc: 0.9021 - val_loss: 0.2974 - val_acc: 0.8920\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.2564 - acc: 0.9054 - val_loss: 0.3335 - val_acc: 0.8808\n"
     ]
    }
   ],
   "source": [
    "val= net.fit(partial_X_train,partial_y_train,epochs=10, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3704 - acc: 0.8717\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = net.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_cnn, y_cnn), (X_test_cnn, y_test_cnn) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn=to_categorical(y_cnn)\n",
    "y_train_cnn=y_cnn\n",
    "y_test_cnn=to_categorical(y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_cnn.reshape((60000, 28,28,1))\n",
    "X_train_cnn = X_train_cnn/255\n",
    "\n",
    "X_test_cnn = X_test_cnn.reshape((10000, 28,28,1))\n",
    "X_test_cnn = X_test_cnn/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.Sequential()\n",
    "net.add(layers.Conv2D(64,[3,3], activation='relu', input_shape=(28,28,1)))\n",
    "net.add(layers.MaxPooling2D((2,2)))\n",
    "net.add(layers.Conv2D(128,[3,3], activation='relu'))\n",
    "net.add(layers.MaxPooling2D((2,2)))\n",
    "net.add(layers.Conv2D(128,[3,3], activation='relu'))\n",
    "net.add(layers.Flatten())\n",
    "net.add(layers.Dense(512, activation='relu')) \n",
    "net.add(layers.Dense(10, activation='softmax')) \n",
    "net.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 817,546\n",
      "Trainable params: 817,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 56s 118ms/step - loss: 0.5290 - acc: 0.8029\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 57s 122ms/step - loss: 0.3075 - acc: 0.8884\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 50s 106ms/step - loss: 0.2574 - acc: 0.9052\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 49s 105ms/step - loss: 0.2241 - acc: 0.9161\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 49s 105ms/step - loss: 0.1956 - acc: 0.9268\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1713 - acc: 0.936 - 51s 108ms/step - loss: 0.1713 - acc: 0.9361\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.1498 - acc: 0.9436\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 57s 121ms/step - loss: 0.1283 - acc: 0.9521\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 78s 165ms/step - loss: 0.1117 - acc: 0.9587\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.0935 - acc: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223834970c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2987 - acc: 0.9124\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = net.evaluate(X_test_cnn,y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0834 - acc: 0.9683\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = net.evaluate(X_train_cnn,y_train_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_cnn = X_train_cnn[:10000]\n",
    "partial_X_train_cnn = X_train_cnn[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_cnn = y_train_cnn[:10000]\n",
    "partial_y_train_cnn = y_train_cnn[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 59s 151ms/step - loss: 0.0822 - acc: 0.9691 - val_loss: 0.0888 - val_acc: 0.9654\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 59s 151ms/step - loss: 0.0668 - acc: 0.9747 - val_loss: 0.0876 - val_acc: 0.9668\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 59s 152ms/step - loss: 0.0569 - acc: 0.9786 - val_loss: 0.0960 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 61s 156ms/step - loss: 0.0496 - acc: 0.9816 - val_loss: 0.1041 - val_acc: 0.9609\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 59s 151ms/step - loss: 0.0415 - acc: 0.9842 - val_loss: 0.1409 - val_acc: 0.9530\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 58s 149ms/step - loss: 0.0399 - acc: 0.9853 - val_loss: 0.1133 - val_acc: 0.9598\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 0.0356 - acc: 0.9870 - val_loss: 0.1371 - val_acc: 0.9549\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 46s 118ms/step - loss: 0.0307 - acc: 0.9887 - val_loss: 0.1312 - val_acc: 0.9558\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 46s 117ms/step - loss: 0.0293 - acc: 0.9895 - val_loss: 0.1758 - val_acc: 0.9477\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 45s 116ms/step - loss: 0.0296 - acc: 0.9894 - val_loss: 0.1712 - val_acc: 0.9539\n"
     ]
    }
   ],
   "source": [
    "val_cnn = net.fit(partial_X_train_cnn,partial_y_train_cnn, epochs=10, batch_size=128,validation_data=(X_val_cnn, y_val_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cnn_dict = val_cnn.history\n",
    "loss = val_cnn_dict['loss']\n",
    "val_loss = val_cnn_dict['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x223839b93c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0, len(loss))\n",
    "plt.plot(x,loss,'bo',label='E')\n",
    "plt.plot(x,val_loss,'ro',label='$E_v$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP와 CNN 비교\n",
    "### MLP의 경우 test accuracy 값이 0.8717 train 한 값이 0.88정도 된다. CNN은 test accuracy 값이 0.9124 train 한 값이 0.96정도이다. test 값은 4.07%, train 한 값은 8%정도로 크게 차이난다. 다만 train 할 때 소요되는 시간은 MLP는 약 17.3초 CNN은 52.8초 정도로 큰 차이를 보인다. 빠른 시간 덜 정확한 분석을 위해서는 MLP를 사용하고 시간이 다소 걸리더라도 높은 정확도를 위해서는 CNN을 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
